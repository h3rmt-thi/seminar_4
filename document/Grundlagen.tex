\section{Grundlagen moderner CPU-Architekturen}
\label{sec:grundlagen-moderner-cpu-architekturen}
Moderne Prozessoren sind deutlich schneller als der Arbeitsspeicher (RAM).
Mit Taktraten von 5 GHz und mehr sowie mindestens 10 Kernen~\cite{ryzen_9} können sie hunderte Befehle ausführen, selbst während sie auf Daten aus dem RAM warten müssen.
Um diese Geschwindigkeitslücke zu überbrücken, nutzen moderne Prozessoren verschiedene Optimierungstechniken, die die Befehlsausführung beschleunigen. \\
Im Folgenden werden diese Optimierungen erläutert, da sie eine zentrale Rolle bei den beschriebenen Angriffen spielen.

\subsection{Cache}
\label{subsec:cache}
Um den Zugriff auf häufig benötigte Daten zu beschleunigen, setzen moderne Prozessoren verschiedene Ebenen von Cache-Speicher ein.
Diese Caches sind direkt in der CPU integriert und bieten deutlich schnelleren Zugriff auf Daten aus dem Arbeitsspeicher (RAM).
Wird ein benötigter Wert nicht im Cache gefunden (Cache Miss), muss er aus dem langsameren RAM nachgeladen werden.
Die CPU lädt dabei die entsprechenden Datenblöcke (Cache Lines) aus dem RAM in den Cache, um zukünftige Zugriffe zu beschleunigen.
Falls notwendig, wird ein bestehender Cache-Eintrag überschrieben, wodurch der alte Wert verloren geht.

\subsection{Out-of-Order Execution}
\label{subsec:out-of-order-execution}
Moderne Prozessoren können die Reihenfolge der Befehlsausführung während der Programmlaufzeit dynamisch anpassen.
Wenn ein Befehl auf einen Wert aus dem RAM wartet, würde dies normalerweise dazu führen, dass nachfolgende Befehle blockiert werden, bis der Wert verfügbar ist und der Befehl ausgeführt werden kann.
Pipelining ist die Technik, die es ermöglicht, mehrere Befehle parallel zu verarbeiten, indem die Ausführung in verschiedene Phasen wie Laden, Berechnen und Speichern unterteilt wird.
Wird beim Laden eines Befehls festgestellt, dass benötigte Werte noch nicht verfügbar sind, wird dieser Befehl in eine Warteschlange verschoben, während andere Befehle, deren Werte bereits verfügbar sind oder keine Abhängigkeit zum blockierenden Befehl haben, geladen und ausgeführt werden können.
Des Weiteren ist es möglich, unabhängige Befehle, wie zum Beispiel eine Multiplikation und eine Division, die verschiedene funktionale Einheiten der CPU nutzen, gleichzeitig auszuführen.
Dies ermöglicht eine höhere Auslastung der CPU und dadurch eine schnellere Programmausführung.

\subsection{Speculative Execution}
\label{subsec:speculative-execution}
Die effektivste Methode zur Beschleunigung der Ausführung von Programmen ist jedoch Werte bereits im Voraus zu berechnen.
Ein Beispiel: In einer Schleife kann die CPU bereits vorab Befehle ausführen, noch bevor feststeht, ob die Schleife tatsächlich durchlaufen wird.
Sobald erkannt wurde, dass die Schleife tatsächlich ausgeführt werden soll, liegen die Ergebnisse dieser Befehle bereits vor und das Programm kann ohne Verzögerung an einer nachfolgenden Stelle fortgesetzt werden.
Werden die berechneten Ergebnisse nicht benötigt, verwirft die CPU diese und setzt die Programmausführung fort.
Idealerweise hat dies keine Auswirkungen auf den ursprünglichen Programmablauf, da die CPU die berechneten Werte vollständig verwirft.
Um die bestmöglichen Vorhersagen über den Programmablauf zu treffen, verwendet die CPU verschiedene Techniken, wie zum Beispiel Branch Prediction.
Branch Prediction ist eine Technik, mit der die CPU versucht, den Ausgang von Branches (Verzweigungen) vorherzusagen.
Beispiele für Branches sind if-Anweisungen oder Schleifen.
Hier muss zur Laufzeit entschieden werden, ob der Code innerhalb der if-Anweisung oder der Schleife ausgeführt werden soll oder nicht.
Die BPU (Branch Prediction Unit) der CPU analysiert den Programmablauf und versucht, bereits im Voraus zu bestimmen, welchen Weg eine Verzweigung vermutlich nehmen wird, um den wahrscheinlichsten Ausführungsweg vorhersagen zu können.